# -*- coding: utf-8 -*-
"""final_project_ml.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BF7_vNNyf_BWvu3MnghoVtF8BfHv8nci

## **Imports**
"""

# imports
import requests
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# SPECIFIALLY FOR MAKING MULTIPLE MODELS
import os
from joblib import dump

"""## **Pull From API**"""

CITY_COORDS = {
    "Los Angeles": (34.0522, -118.2437),
    "Madrid":      (40.4168, -3.7038),
    "London":      (51.5074, -0.1278),
}

# API is in celsius, swap to fahrenheit
def c_to_f(celsius):
    return (celsius * 9/5) + 32

# Pull from API
# We pull 60 days for a good span of data but we keep a window focused (as shown
# later in dataset function) on the past 7 days
def get_weather_history(latitude, longitude, days=60):
    end = datetime.now().date() - timedelta(days=1) # Today (API is in diff timezone)

    # Start 'days-1' before end so total rows = `days`
    start = end - timedelta(days=days-1)

    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        "latitude": latitude,
        "longitude": longitude,
        "start_date": start.strftime("%Y-%m-%d"),
        "end_date": end.strftime("%Y-%m-%d"),
        "daily": "temperature_2m_max",
        "timezone": "America/Los_Angeles" # Our timezone for reference
    }

    response = requests.get(url, params=params)
    data = response.json()

    df = pd.DataFrame({
       "date": data["daily"]["time"],
       "temp": data["daily"]["temperature_2m_max"]
    })

    # Convert to datetime
    df["date"] = pd.to_datetime(df["date"])

    # Convert Celsius → Fahrenheit
    df["temp"] = df["temp"].apply(c_to_f)

    return df

def convert_name(name: str) -> str:
    return name.lower().replace(" ", "_")

"""## **Make the Dataset**"""

def make_regression_dataset(series, window=7):
    X = []
    y = []
    for i in range(window, len(series)):
        X.append(series[i-window:i])
        y.append(series[i])
    return np.array(X), np.array(y)

"""## **Build, Train, and Test**"""

def train_city_model(city_name, lat, lon, days=60, window=7):
    df = get_weather_history(lat, lon, days=days)
    temps = df["temp"].values

    X, y = make_regression_dataset(temps, window=window)
    print(f"{city_name}: X shape = {X.shape}, y shape = {y.shape}")

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, shuffle=False
    )

    # For this ML, we don't need to use epochs to train since our model solves
    # in one step (using linear regression)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    model = LinearRegression()
    model.fit(X_train_scaled, y_train)

    # Check accuracy
    y_pred = model.predict(X_test_scaled)
    mae = np.mean(np.abs(y_test - y_pred))
    print(f"{city_name}: MAE on test set = {mae:.2f} °F")

    return model, scaler

"""## **Evaluate the Model**"""

def train_and_save_all_models(output_dir="models", days=60, window=7):
    os.makedirs(output_dir, exist_ok=True)

    for city, (lat, lon) in CITY_COORDS.items():
        model, scaler = train_city_model(city, lat, lon, days=days, window=window)

        city_name = convert_name(city)
        model_path = os.path.join(output_dir, f"{city_name}_model.joblib")
        scaler_path = os.path.join(output_dir, f"{city_name}_scaler.joblib")

        dump(model, model_path)
        dump(scaler, scaler_path)

if __name__ == "__main__":
    train_and_save_all_models()